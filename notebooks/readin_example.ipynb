{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read-in example of the synthesis logs with plotting\n",
    "\n",
    "This notebook shows an example on how to read interesting informatino from the synthesis files, and plot such information.\n",
    "\n",
    "**Note:** Expects HDF5 files (\\*.h5) in directory `tests/testdata`. They can be generated by running `sh scripts/RunMultiple.sh` from the top-level source directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import h5py\n",
    "import nexusformat.nexus as nx # makes it easier to extract information. \n",
    "import numpy as np\n",
    "from attrs import Factory\n",
    "from attrs import define, validators, field, cmp_using, fields\n",
    "import pandas as pd\n",
    "\n",
    "import logging\n",
    "from typing import Iterable\n",
    "from typing import Any, NoReturn\n",
    "\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up some flexible HDF reading methods (copied from DataMerge dataclasses and readers for now): \n",
    "\n",
    "# Mixin class for making a dict-like object out of an attrs class\n",
    "# from: https://github.com/python-attrs/attrs/issues/879\n",
    "\n",
    "import yaml\n",
    "\n",
    "class gimmeItems:  # used to be MutableMappingMixin(MutableMapping)\n",
    "    \"\"\"Mixin class to make attrs classes quack like a dictionary (well,\n",
    "    technically a mutable mapping). ONLY use this with attrs classes.\n",
    "\n",
    "    Provides keys(), values(), and items() methods in order to be\n",
    "    dict-like in addition to MutableMapping-like. Also provides pop(),\n",
    "    but it just raises a TypeError :)\n",
    "    \"\"\"\n",
    "\n",
    "    __slots__ = ()  # May as well save on memory?\n",
    "\n",
    "    def __iter__(self) -> Iterable:\n",
    "        for ifield in fields(self.__class__):\n",
    "            yield ifield.name\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(fields(self.__class__))\n",
    "\n",
    "    def __getitem__(self, k: str) -> Any:\n",
    "        \"\"\"\n",
    "        Adapted from:\n",
    "        https://github.com/python-attrs/attrs/issues/487#issuecomment-660727537\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return self.__getattribute__(k)\n",
    "        except AttributeError as exc:\n",
    "            raise KeyError(str(exc)) from None\n",
    "\n",
    "    def __delitem__(self, v: str) -> NoReturn:\n",
    "        raise TypeError(\"Cannot delete fields for attrs classes.\")\n",
    "\n",
    "    def __setitem__(self, k: str, v: Any) -> None:\n",
    "        self.__setattr__(k, v)\n",
    "\n",
    "    def pop(self, key, default=None) -> NoReturn:\n",
    "        raise TypeError(\"Cannot pop fields from attrs classes.\")\n",
    "\n",
    "    def keys(self) -> Iterable:\n",
    "        return self.__iter__()\n",
    "\n",
    "    def values(self) -> Iterable:\n",
    "        for key in self.__iter__():\n",
    "            yield self.__getattribute__(key)\n",
    "\n",
    "    def items(self) -> Iterable:\n",
    "        for key in self.__iter__():\n",
    "            yield key, self.__getattribute__(key)\n",
    "\n",
    "# end copy\n",
    "\n",
    "# First, we set the read names and locations here:\n",
    "@define\n",
    "class HDFPathsObj(gimmeItems):\n",
    "    \"\"\"\n",
    "    Config carrying the HDF5 path locations for reading datafiles.\n",
    "    \"\"\"\n",
    "\n",
    "    # Q: str = field(\n",
    "    #     default=\"/entry/result/Q\", validator=validators.instance_of(str), converter=str\n",
    "    # )\n",
    "    # I: str = field(\n",
    "    #     default=\"/entry/result/I\", validator=validators.instance_of(str), converter=str\n",
    "    # )\n",
    "    # ISigma: str = field(\n",
    "    #     default=\"/entry/result/ISigma\",\n",
    "    #     validator=validators.instance_of(str),\n",
    "    #     converter=str,\n",
    "    # )\n",
    "    SampleID: str = field(\n",
    "        default=\"/DACHS/Synthesis/RawLog/0/SampleID\", # hdf5 location\n",
    "        validator=validators.instance_of(str), # locations are in string format\n",
    "        converter=str,\n",
    "    )\n",
    "    ExperimentID: str = field(\n",
    "        default=\"/DACHS/Synthesis/RawLog/0/ExperimentID\",\n",
    "        validator=validators.instance_of(str),\n",
    "        converter=str,\n",
    "    )    \n",
    "    InjectionSpeed: str = field(\n",
    "        default=\"/DACHS/Synthesis/DerivedParameters/InjectionSpeed\", # hdf5 location\n",
    "        validator=validators.instance_of(str), # locations are in string format\n",
    "        converter=str,\n",
    "    )\n",
    "    # not able to read attributes yet\n",
    "    # InjectionSpeedUnits: str = field(\n",
    "    #     default=\"/AutoMOF5/MOF_synthesis_1/ExtraInformation/InjectionSpeed\",\n",
    "    #     validator=validators.instance_of(str),\n",
    "    #     converter=str,\n",
    "    # )\n",
    "    MetalToLinkerRatio: str = field(\n",
    "        default=\"/DACHS/Synthesis/DerivedParameters/MetalToLinkerRatio\", # hdf5 location\n",
    "        validator=validators.instance_of(str), # locations are in string format\n",
    "        converter=str,\n",
    "    )\n",
    "    MetalToMethanolRatio: str = field(\n",
    "        default=\"/DACHS/Synthesis/DerivedParameters/MetalToMethanolRatio\",\n",
    "        validator=validators.instance_of(str),\n",
    "        converter=str,\n",
    "    )\n",
    "    ReactionTime: str = field(\n",
    "        default=\"/DACHS/Synthesis/DerivedParameters/ReactionTime\",\n",
    "        validator=validators.instance_of(str),\n",
    "        converter=str,\n",
    "    )    \n",
    "    SynthesisYield: str = field(\n",
    "        default=\"/DACHS/Chemicals/SynthesisYield\",\n",
    "        validator=validators.instance_of(str),\n",
    "        converter=str,\n",
    "    )\n",
    "\n",
    "# then we configure the defaults for the same: \n",
    "@define\n",
    "class HDFDefaultsObj(gimmeItems):\n",
    "    \"\"\"In case the preset HDF5 paths are empty, defaults can be used for some non-critical items\"\"\"\n",
    "\n",
    "    SampleID: str = field(\n",
    "        default=\"\", validator=validators.instance_of(str), converter=str\n",
    "    )\n",
    "    ExperimentID: str = field(\n",
    "        default=\"\", validator=validators.instance_of(str), converter=str\n",
    "    )\n",
    "    # I guess these should be pint Units at some point. \n",
    "    InjectionSpeed: float = field(\n",
    "        default=0.0, # hdf5 location\n",
    "        validator=validators.instance_of(float), # locations are in string format\n",
    "        converter=float,\n",
    "    )\n",
    "    MetalToLinkerRatio: float = field(\n",
    "        default=0.0, # hdf5 location\n",
    "        validator=validators.instance_of(float), # locations are in string format\n",
    "        converter=float,\n",
    "    )\n",
    "    MetalToMethanolRatio: float = field(\n",
    "        default=0.0, # hdf5 location\n",
    "        validator=validators.instance_of(float), # locations are in string format\n",
    "        converter=float,\n",
    "    )\n",
    "    ReactionTime: float = field(\n",
    "        default=0.0, # hdf5 location\n",
    "        validator=validators.instance_of(float), # locations are in string format\n",
    "        converter=float,\n",
    "    )\n",
    "    SynthesisYield: float = field(\n",
    "        default=0.0, # hdf5 location\n",
    "        validator=validators.instance_of(float), # locations are in string format\n",
    "        converter=float,\n",
    "    )\n",
    "\n",
    "\n",
    "@define\n",
    "class readConfigObj(gimmeItems):\n",
    "    \"\"\"\n",
    "    Object that carries information on how to read the datafiles\n",
    "    \"\"\"\n",
    "\n",
    "    hdfPaths: HDFPathsObj = field(\n",
    "        default=Factory(HDFPathsObj),\n",
    "        validator=validators.instance_of(HDFPathsObj),\n",
    "    )\n",
    "\n",
    "    hdfDefaults: HDFDefaultsObj = field(\n",
    "        default=Factory(HDFDefaultsObj),\n",
    "        validator=validators.instance_of(HDFDefaultsObj),\n",
    "    )\n",
    "\n",
    "# this could be used to read the configuration from yaml files: \n",
    "def readConfigObjFromYaml(filename: Path) -> readConfigObj:\n",
    "    assert (\n",
    "        filename.is_file()\n",
    "    ), f\"Read configuration filename {filename.as_posix()} does not exist\"\n",
    "    with open(filename, \"r\") as f:\n",
    "        configDict = yaml.safe_load(f)\n",
    "    if \"readConfig\" not in configDict.keys():\n",
    "        return readConfigObj(HDFPathsObj(), HDFDefaultsObj())\n",
    "    print(configDict[\"readConfig\"])\n",
    "    HDFPaths = HDFPathsObj(**configDict[\"readConfig\"].get(\"HDFPaths\", {}))\n",
    "    HDFDefaults = HDFDefaultsObj(**configDict[\"readConfig\"].get(\"HDFDefaults\", {}))\n",
    "    return readConfigObj(HDFPaths, HDFDefaults)\n",
    "\n",
    "\n",
    "# now for the actual reader, modified here slightly to output to Pandas Dataframe:\n",
    "def scatteringDataObjFromNX(\n",
    "    filename: Path, readConfig: readConfigObj\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Returns a populated scatteringDataObj by reading the data from a Processed MOUSE NeXus file\"\"\"\n",
    "    assert filename.is_file(), logging.warning(\n",
    "        f'{filename=} cannot be accessed from {Path(\".\").absolute().as_posix()}'\n",
    "    )\n",
    "    with h5py.File(filename, \"r\") as h5f:\n",
    "        kvs = {}\n",
    "        for key in readConfig.hdfPaths.keys():\n",
    "            hPath = getattr(readConfig.hdfPaths, key)\n",
    "            #print(f\"{key=}, {hPath=}\")\n",
    "            if hPath in h5f:\n",
    "                val = h5f[hPath]\n",
    "                #print(f\"  {val=}\", type(val))\n",
    "                try:\n",
    "                    val = val[()]  # access the scalar value of a dataset\n",
    "                except TypeError:\n",
    "                    val = val[\"Quantity\"]\n",
    "                    val = val[()]  # access the scalar value of a dataset, 2nd try\n",
    "                if isinstance(val, np.ndarray):\n",
    "                    val = val.flatten()\n",
    "            else:\n",
    "                assert key in readConfig.hdfDefaults.keys(), logging.error(\n",
    "                    f\"NeXus file {filename=} does not contain information for {key=} at specified HDF5 Path {hPath}\"\n",
    "                )\n",
    "                val = getattr(readConfig.hdfDefaults, key)\n",
    "            if isinstance(val, bytes): val=val.decode('utf-8')\n",
    "            kvs.update({key: val})\n",
    "\n",
    "    return pd.DataFrame(data=kvs, index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filesH5 = list((Path().resolve().parent / 'tests/testData/').glob('*AutoMOFs*.h5'))\n",
    "if not len(filesH5):\n",
    "    raise Warning(\"No HDF5 archive files found, ie. generated yet!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iList = []\n",
    "for filename in filesH5:\n",
    "    iList += [scatteringDataObjFromNX(filename, readConfigObj())]\n",
    "info = pd.concat(iList, axis=0, ignore_index=True)\n",
    "info['SampleID'] = info['SampleID'].str.strip()\n",
    "info['ReactionType'] = info['SampleID'].str[:1]\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbreg": {
     "diff_ignore": [
      "/outputs/*/data"
     ]
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig=px.scatter(data_frame=info, x='ReactionTime', y='SynthesisYield', color='ReactionType', size='MetalToLinkerRatio', hover_data=info.keys(), log_x=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the demo from the website, modified slightly to use jupyter_dash\n",
    "\n",
    "from dash import Dash, html, dcc, Input, Output\n",
    "#from jupyter_dash import JupyterDash\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "external_stylesheets = ['https://codepen.io/chriddyp/pen/bWLwgP.css']\n",
    "\n",
    "app = Dash(__name__, external_stylesheets=external_stylesheets)\n",
    "\n",
    "df = info # pd.read_csv('https://plotly.github.io/datasets/country_indicators.csv')\n",
    "\n",
    "\n",
    "app.layout = html.Div([\n",
    "    html.Div([\n",
    "\n",
    "        html.Div([\n",
    "            dcc.Dropdown(\n",
    "                df.keys().unique(),\n",
    "                'ReactionTime',\n",
    "                id='crossfilter-xaxis-column',\n",
    "            ),\n",
    "            dcc.RadioItems(\n",
    "                ['Linear', 'Log'],\n",
    "                'Linear',\n",
    "                id='crossfilter-xaxis-type',\n",
    "                labelStyle={'display': 'inline-block', 'marginTop': '5px'}\n",
    "            )\n",
    "        ],\n",
    "        style={'width': '49%', 'display': 'inline-block'}),\n",
    "\n",
    "        html.Div([\n",
    "            dcc.Dropdown(\n",
    "                df.keys().unique(),\n",
    "                'SynthesisYield',\n",
    "                id='crossfilter-yaxis-column'\n",
    "            ),\n",
    "            dcc.RadioItems(\n",
    "                ['Linear', 'Log'],\n",
    "                'Linear',\n",
    "                id='crossfilter-yaxis-type',\n",
    "                labelStyle={'display': 'inline-block', 'marginTop': '5px'}\n",
    "            )\n",
    "        ], style={'width': '49%', 'float': 'right', 'display': 'inline-block'})\n",
    "    ], style={\n",
    "        'padding': '10px 5px'\n",
    "    }),\n",
    "\n",
    "    html.Div([\n",
    "        dcc.Graph(\n",
    "            id='crossfilter-indicator-scatter',\n",
    "            hoverData={'points': [{'customdata': 'Japan'}]}\n",
    "        )\n",
    "    ], style={'width': '80%', 'display': 'inline-block', 'padding': '0 20'}),\n",
    "    # html.Div([\n",
    "    #     dcc.Graph(id='x-time-series'),\n",
    "    #     dcc.Graph(id='y-time-series'),\n",
    "    # ], style={'display': 'inline-block', 'width': '49%'}),\n",
    "\n",
    "    # html.Div(dcc.Slider(\n",
    "    #     df['MetalToLinkerRatio'].min(),\n",
    "    #     df['MetalToLinkerRatio'].max(),\n",
    "    #     step=None,\n",
    "    #     id='crossfilter-year--slider',\n",
    "    #     value=df['MetalToLinkerRatio'].max(),\n",
    "    #     marks={str(MetalToLinkerRatio): str(MetalToLinkerRatio) for MetalToLinkerRatio in df['MetalToLinkerRatio'].unique()}\n",
    "    # ), style={'width': '49%', 'padding': '0px 20px 20px 20px'})\n",
    "])\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output('crossfilter-indicator-scatter', 'figure'),\n",
    "    Input('crossfilter-xaxis-column', 'value'),\n",
    "    Input('crossfilter-yaxis-column', 'value'),\n",
    "    Input('crossfilter-xaxis-type', 'value'),\n",
    "    Input('crossfilter-yaxis-type', 'value'),\n",
    "    # Input('crossfilter-year--slider', 'value')\n",
    "    )\n",
    "\n",
    "def update_graph(xaxis_column_name, yaxis_column_name,\n",
    "                 xaxis_type, yaxis_type,\n",
    "                 ):\n",
    "    # dff = df[df['MetalToLinkerRatio'] == year_value]\n",
    "    dff = df\n",
    "    fig = px.scatter(data_frame=dff, x=xaxis_column_name,\n",
    "            y=yaxis_column_name,\n",
    "            color='ReactionType',\n",
    "            size='MetalToLinkerRatio',\n",
    "            hover_data=dff.keys(),\n",
    "            hover_name='SampleID', # dff[yaxis_column_name]\n",
    "            )\n",
    "    \n",
    "    # fig=px.scatter(data_frame=info, x='ReactionTime', y='SynthesisYield', color='ReactionType', size='MetalToLinkerRatio', hover_data=info.keys(), log_x=True)\n",
    "\n",
    "    fig.update_traces(customdata=dff) # [yaxis_column_name])\n",
    "\n",
    "    fig.update_xaxes(title=xaxis_column_name, type='linear' if xaxis_type == 'Linear' else 'log')\n",
    "\n",
    "    fig.update_yaxes(title=yaxis_column_name, type='linear' if yaxis_type == 'Linear' else 'log')\n",
    "\n",
    "    fig.update_layout(margin={'l': 40, 'b': 40, 't': 10, 'r': 0}, hovermode='closest')\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "# def create_time_series(dff, axis_type, title):\n",
    "\n",
    "#     fig = px.scatter(dff, x='MetalToLinkerRatio', y='MetalToLinkerRatio')\n",
    "\n",
    "#     fig.update_traces(mode='lines+markers')\n",
    "\n",
    "#     fig.update_xaxes(showgrid=False)\n",
    "\n",
    "#     fig.update_yaxes(type='linear' if axis_type == 'Linear' else 'log')\n",
    "\n",
    "#     fig.add_annotation(x=0, y=0.85, xanchor='left', yanchor='bottom',\n",
    "#                        xref='paper', yref='paper', showarrow=False, align='left',\n",
    "#                        text=title)\n",
    "\n",
    "#     fig.update_layout(height=225, margin={'l': 20, 'b': 30, 'r': 10, 't': 10})\n",
    "\n",
    "#     return fig\n",
    "\n",
    "\n",
    "# @app.callback(\n",
    "#     Output('x-time-series', 'figure'),\n",
    "#     Input('crossfilter-indicator-scatter', 'hoverData'),\n",
    "#     Input('crossfilter-xaxis-column', 'value'),\n",
    "#     Input('crossfilter-xaxis-type', 'value'))\n",
    "# def update_y_timeseries(hoverData, xaxis_column_name, axis_type):\n",
    "#     country_name = hoverData['points'][0]['customdata']\n",
    "#     dff = df[df['MetalToLinkerRatio'] == country_name]\n",
    "#     dff = dff[dff['MetalToLinkerRatio'] == xaxis_column_name]\n",
    "#     title = '<b>{}</b><br>{}'.format(country_name, xaxis_column_name)\n",
    "#     return create_time_series(dff, axis_type, title)\n",
    "\n",
    "\n",
    "# @app.callback(\n",
    "#     Output('y-time-series', 'figure'),\n",
    "#     Input('crossfilter-indicator-scatter', 'hoverData'),\n",
    "#     Input('crossfilter-yaxis-column', 'value'),\n",
    "#     Input('crossfilter-yaxis-type', 'value'))\n",
    "# def update_x_timeseries(hoverData, yaxis_column_name, axis_type):\n",
    "#     dff = df[df['MetalToLinkerRatio'] == hoverData['points'][0]['customdata']]\n",
    "#     dff = dff[dff['MetalToLinkerRatio'] == yaxis_column_name]\n",
    "#     return create_time_series(dff, axis_type, yaxis_column_name)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(jupyter_mode='external')#, debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
